{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7abeca-7511-4e3d-82d8-429e4c1a60c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Pkg\n",
    "#Pkg.add(\"JSON\")\n",
    "#Pkg.add(\"Clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6dbb21-2974-4946-b780-7ef27b8a230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a357b90c-9e97-4cae-8b20-6da5aec114b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# カレントフォルダにある拡張子が「txt」のファイル名の一覧\n",
    "files = filter(f -> isfile(f)&&occursin(r\".txt$\", f), readdir(\".\"))\n",
    "# 複数回に分けられて取得したjsonデータをマージする\n",
    "urls = []     # 記事の重複判定用\n",
    "articles = []   # 重複を覗いた記事\n",
    "days = Dict{String, Int}()\n",
    "categories = Dict{String, Int}()\n",
    "for file in files\n",
    "    data = JSON.parsefile(file)\n",
    "    for d in data\n",
    "        url = d[\"url\"]\n",
    "        if !(url in urls)\n",
    "            push!(articles, d)\n",
    "            day = split(d[\"datetime\"])[1]\n",
    "            days[day] = get(days, day, 0) + 1\n",
    "            category = d[\"category\"]\n",
    "            categories[category] = get(categories, category, 0) + 1\n",
    "            push!(urls, url)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08aa7282-c435-415d-818b-44bb9668be3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d717d0-5e26-44bb-9c30-3448f2256a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Int64} with 23 entries:\n",
       "  \"6/28(火… => 86\n",
       "  \"7/2(土)\" => 71\n",
       "  \"7/6(水)\" => 92\n",
       "  \"7/8(金)\" => 98\n",
       "  \"7/5(火)\" => 81\n",
       "  \"7/1(金)\" => 83\n",
       "  \"7/4(月)\" => 77\n",
       "  \"6/26(日… => 65\n",
       "  \"6/25(土… => 73\n",
       "  \"6/27(月… => 81\n",
       "  \"6/29(水… => 94\n",
       "  \"7/12(火… => 79\n",
       "  \"7/9(土)\" => 64\n",
       "  \"6/22(水… => 10\n",
       "  \"7/13(水… => 2\n",
       "  \"7/10(日… => 67\n",
       "  \"6/24(金… => 72\n",
       "  \"7/11(月… => 109\n",
       "  \"6/21(火… => 2\n",
       "  \"6/30(木… => 90\n",
       "  \"7/3(日)\" => 63\n",
       "  \"6/23(木… => 7\n",
       "  \"7/7(木)\" => 96"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 発信日ごとの記事数\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2a241c-b5a8-4ee7-9caa-8d35e1ce3e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Int64} with 8 entries:\n",
       "  \"local\"         => 301\n",
       "  \"domestic\"      => 317\n",
       "  \"sports\"        => 204\n",
       "  \"entertainment\" => 176\n",
       "  \"science\"       => 79\n",
       "  \"it\"            => 100\n",
       "  \"world\"         => 192\n",
       "  \"business\"      => 193"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# カテゴリごとの記事数\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7a410a-39bd-4185-9999-7d21d101c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# マージされた記事を保存\n",
    "filename = \"yahoo_merged.txt\"\n",
    "open(filename, \"w\") do f\n",
    "    println(f, json(articles))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c6eff0-328c-4722-98c4-485bec8a5b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getlines (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# クレンジング\n",
    "# 記事文字列からテキストデータを抽出し、形態素解析できるように加工する\n",
    "#   ・句点で改行させ、不要な空白・空行を除去\n",
    "function getlines(article::String)\n",
    "    new_lines = []\n",
    "    # 形態素解析に長文を渡したり、不要な呼び出しをしないように、文字列を調整\n",
    "    ## 句点「。」の後で分割する\n",
    "    lines = split(replace(article, r\"。\" => \"。\\n\"), \"\\n\")\n",
    "    for ll in lines\n",
    "        ## 行頭の空白文字列を削除\n",
    "        ll = replace(ll, r\"^[　 ]+\" => \"\")\n",
    "        ## 空行は削除\n",
    "        if length(ll) == 0\n",
    "            continue\n",
    "        end\n",
    "        # 処理済み文字列を格納\n",
    "        push!(new_lines, ll)\n",
    "    end\n",
    "    new_lines\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e707bb41-1808-4a8e-9df3-33285ae0b49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "countword (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 形態素解析して、語の一覧を返す\n",
    "using Awabi\n",
    "# 形態素解析器の設定\n",
    "## Linux / Mac\n",
    "#tokenizer = Tokenizer()\n",
    "## Windows：\n",
    "#dic = Dict(\"dicdir\" => \"C:\\\\Program Files (x86)\\\\MeCab\\\\dic\\\\ipadic\")\n",
    "#tokenizer = Tokenizer(dic)\n",
    "## SageMaker Studio Lab\n",
    "rcfile = \"/home/studio-lab-user/mecab/etc/mecabrc\"\n",
    "tokenizer = Tokenizer(rcfile)\n",
    "\n",
    "function countword(tokenizer, lines)\n",
    "    # 数え上げ格納領域\n",
    "    word_counts = Dict{String, Int}()\n",
    "    doc_counts = Dict{String, Int}()\n",
    "\n",
    "    # 形態素解析＆数え上げ\n",
    "    for line in lines\n",
    "        # 1文を形態素解析\n",
    "        tokens = tokenize(tokenizer, line)\n",
    "        new_tokens = []\n",
    "        for token in tokens\n",
    "            attr = split(token[2], \",\")\n",
    "            hinsi = attr[1]\n",
    "            surface = token[1] # 表記\n",
    "            basic = (attr[7] != \"*\") ? attr[7] : surface   # 形態素の基本形\n",
    "            ## \n",
    "            if hinsi in [\"名詞\", \"動詞\", \"形容詞\", \"副詞\"] \n",
    "                push!(new_tokens, basic)\n",
    "            end\n",
    "        end\n",
    "        # 形態素数を数え上げ\n",
    "        for surface in new_tokens\n",
    "            word_counts[surface] = get(word_counts, surface, 0) + 1\n",
    "            doc_counts[surface] = 1\n",
    "        end\n",
    "    end\n",
    "    (word_counts, doc_counts)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a213d76-24bd-4b89-94ef-75dd50a22ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_tfidf_vector (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TF=単語頻度\n",
    "function mergeword(list_word_counts)\n",
    "    all_word_counts = Dict{String, Int}()\n",
    "    for wc in list_word_counts\n",
    "        mergewith!(+, all_word_counts, wc)  # Dictの合成、値は+演算\n",
    "    end\n",
    "    all_word_counts\n",
    "end\n",
    "\n",
    "# DF＝文書頻度（単語がいくつの文書に出現したかの数）\n",
    "function mergedf(list_doc_counts)\n",
    "    all_doc_counts = Dict{String, Int}()\n",
    "    for dc in list_doc_counts\n",
    "        mergewith!(+, all_doc_counts, dc)  # Dictの合成、値は+演算\n",
    "    end\n",
    "    all_doc_counts\n",
    "end\n",
    "\n",
    "# tf-idf 作成\n",
    "function make_tfidf_vector(label_pos, list_word_counts, all_doc_counts)\n",
    "    n = length(list_word_counts)  # 文書数＝記事数\n",
    "    println(n)\n",
    "    list_tfidf_vector = []\n",
    "    for tfs in list_word_counts\n",
    "        # 1記事分\n",
    "        vec = zeros(Float64, length(label_pos))\n",
    "        for (w, tf) in tfs\n",
    "            df = get(all_doc_counts, w, 0)\n",
    "            if df != 0\n",
    "                pos = get(label_pos, w, 0)\n",
    "                if pos != 0\n",
    "                    idf = log(n / df) + 1\n",
    "                    vec[pos] = tf * idf\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        push!(list_tfidf_vector, vec)\n",
    "    end\n",
    "    list_tfidf_vector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba5ae529-4b2c-4e58-aee1-408fc5d461f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.934205922"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 時間かかるので、測定してみる\n",
    "@elapsed begin\n",
    "    # 特徴ベクトル（TF-IDF）の作成\n",
    "    ## 記事ごとの単語と頻度の一覧\n",
    "    list_word_counts = []\n",
    "    list_doc_counts = []\n",
    "    for article in articles\n",
    "        text = article[\"detail\"]\n",
    "        lines = getlines(text)\n",
    "        (wcs, dcs) = countword(tokenizer, lines)\n",
    "        push!(list_word_counts, wcs)\n",
    "        push!(list_doc_counts, dcs)\n",
    "        article[\"word_count\"] = wcs\n",
    "    end\n",
    "    ## 全体の単語と頻度の一覧を作成\n",
    "    all_word_counts = mergeword(list_word_counts)\n",
    "    all_doc_counts =  mergedf(list_doc_counts)\n",
    "    ## 全体の単語一覧\n",
    "    labels = sort(collect(keys(all_word_counts)))\n",
    "    label_pos = Dict([(w, pos) for (pos, w) in enumerate(labels)])\n",
    "    ## 各記事ごとの単語ベクトル（Bag of Words）作成\n",
    "    list_vector = make_tfidf_vector(label_pos, list_word_counts, all_doc_counts)\n",
    "\n",
    "    # 行列に変換する. juliaはcolumn-major order\n",
    "    mat = hcat(list_vector...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f02d86a-93c9-45f8-9503-2bc5980315cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562-element Vector{Int64}:\n",
       " 4\n",
       " 7\n",
       " 4\n",
       " 5\n",
       " 7\n",
       " 4\n",
       " 4\n",
       " 6\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 2\n",
       " 4\n",
       " ⋮\n",
       " 6\n",
       " 7\n",
       " 6\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distances\n",
    "using Clustering\n",
    "\n",
    "# K-meansを使って、利用してカテゴリー数8個のクラスタに分類する\n",
    "n_clusters = 8 #the number of clusters\n",
    "result = kmeans(mat, n_clusters; maxiter=200, display=:none, distance=CosineDist())\n",
    "@assert nclusters(result) == n_clusters # verify the number of clusters\n",
    "clust_numbers = assignments(result) # get the assignments of points to clusters\n",
    "#cluster_sizes = counts(result) # get the cluster sizes\n",
    "#cluster_centers = result.centers # get the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c208369c-b324-4918-b8c4-a9fa259a0fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Vector{Int64}} with 8 entries:\n",
       "  \"local\"         => [3, 41, 3, 68, 18, 33, 131, 4]\n",
       "  \"domestic\"      => [10, 92, 17, 120, 19, 16, 25, 18]\n",
       "  \"sports\"        => [4, 2, 21, 2, 94, 54, 27, 0]\n",
       "  \"entertainment\" => [0, 2, 7, 3, 10, 19, 135, 0]\n",
       "  \"science\"       => [0, 21, 0, 0, 11, 10, 37, 0]\n",
       "  \"it\"            => [10, 3, 4, 2, 4, 6, 71, 0]\n",
       "  \"world\"         => [7, 2, 0, 34, 6, 12, 21, 110]\n",
       "  \"business\"      => [59, 19, 1, 4, 10, 27, 67, 6]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 元のカテゴリーと、クラスタリングの結果を比較する\n",
    "# カテゴリごとに、各クラスタに含まれる記事数を求める\n",
    "check_table = Dict([(name, zeros(Int, n_clusters)) for name in keys(categories)])\n",
    "for (clust_no, article) in zip(clust_numbers, articles)\n",
    "    category = article[\"category\"]\n",
    "    check_table[category][clust_no] += 1\n",
    "end\n",
    "check_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab13bf0-3f66-4ef0-b32d-fe9412076a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Julia (4 threads) 1.7.2",
   "language": "julia",
   "name": "conda-env-default-julia-_4-threads_-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
